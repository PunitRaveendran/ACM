{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1WOoKSgsH+0dsC4j912kr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PunitRaveendran/ACM/blob/main/Feature%20Showdown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFqWKG-c6brO",
        "outputId": "d5bc61d3-91cc-4304-c321-d5a0d717a215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Selected Features (after preprocessing): ['BurnoutLevel', 'ProductivityScore', 'StressLevel']\n",
            "Corresponding Original Top 3 Features: ['BurnoutLevel', 'ProductivityScore', 'StressLevel']\n",
            "\n",
            "--- Minimal Burnout Model ---\n",
            "Chosen Original Features: ['BurnoutLevel', 'ProductivityScore', 'StressLevel']\n",
            "Accuracy on Test Set: 99.889%\n",
            "Cross-Validation Accuracy: 99.80% (+/- 0.19%)\n",
            "The selected top 3 features are likely  to be strong indicators of burnout risk based on Random Forest's conclusion of their predictive power.\n",
            "Training a minimal model on these features helps understand the core drivers of burnout in the dataset and potentially uilding a simpler,more  interpretabble model\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# 3-Feature Showdown â€“ Burnout Prediction\n",
        "# -------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Load your burnout dataset\n",
        "# -----------------------------------\n",
        "df = pd.read_csv(\"/content/mental_health_workplace_survey.csv\")\n",
        "\n",
        "# Corrected feature names based on the dataframe\n",
        "all_features = ['WorkHoursPerWeek', 'JobSatisfaction', 'SleepHours',\n",
        "                'Age', 'YearsAtCompany', 'SalaryRange', 'TeamSize',\n",
        "                'StressLevel', 'ProductivityScore', 'BurnoutLevel',\n",
        "                'PhysicalActivityHrs', 'CommuteTime', 'HasMentalHealthSupport',\n",
        "                'ManagerSupportScore', 'HasTherapyAccess', 'MentalHealthDaysOff',\n",
        "                'WorkLifeBalanceScore', 'CareerGrowthScore', 'Gender', 'Country',\n",
        "                'JobRole', 'Department', 'RemoteWork']\n",
        "\n",
        "# Corrected target variable name\n",
        "y = df['BurnoutRisk']\n",
        "X_all = df[all_features]\n",
        "\n",
        "# Identify categorical and numerical columns for preprocessing\n",
        "cat_cols = X_all.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "num_cols = X_all.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline for all features\n",
        "preprocessor_all = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), cat_cols),\n",
        "        ('num', StandardScaler(), num_cols)\n",
        "    ],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X_all_processed = preprocessor_all.fit_transform(X_all)\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Selecting top 3 features using Random Forest feature importance\n",
        "# -----------------------------------\n",
        "rf = RandomForestClassifier(random_state=46)\n",
        "rf.fit(X_all_processed, y)\n",
        "\n",
        "# Get feature names after one-hot encoding\n",
        "ohe_feature_names = preprocessor_all.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
        "all_processed_feature_names = list(ohe_feature_names) + num_cols\n",
        "\n",
        "importances = pd.Series(rf.feature_importances_, index=all_processed_feature_names)\n",
        "importances = importances.sort_values(ascending=False)\n",
        "\n",
        "top3_features_processed = importances.head(3).index.tolist()\n",
        "print(\"Top 3 Selected Features (after preprocessing):\", top3_features_processed)\n",
        "\n",
        "\n",
        "# To map back to original features, we can inspect the selected processed feature names\n",
        "# and see which original columns they correspond to.\n",
        "original_top3_features = []\n",
        "for feature in top3_features_processed:\n",
        "    if feature in num_cols and feature not in original_top3_features:\n",
        "        original_top3_features.append(feature)\n",
        "    else:\n",
        "        for col in cat_cols:\n",
        "            if feature.startswith(col + '_') and col not in original_top3_features:\n",
        "                original_top3_features.append(col)\n",
        "                break # Stop searching once the original column is found\n",
        "\n",
        "\n",
        "print(\"Corresponding Original Top 3 Features:\", original_top3_features)\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Train minimal model (Logistic Regression) on these 3 features\n",
        "# -----------------------------------\n",
        "X_top3_orig = df[original_top3_features]\n",
        "\n",
        "# Create a new preprocessor for the top 3 original features\n",
        "top3_cat_cols_orig = X_top3_orig.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "top3_num_cols_orig = X_top3_orig.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "preprocessor_top3 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), top3_cat_cols_orig),\n",
        "        ('num', StandardScaler(), top3_num_cols_orig)\n",
        "    ],\n",
        "    remainder='passthrough')\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top3_orig, y, test_size=0.3, random_state=46, stratify=y)\n",
        "\n",
        "\n",
        "# Create pipeline for Logistic Regression with top 3 features\n",
        "log_reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor_top3), ('classifier', LogisticRegression(max_iter=1500, random_state=46))])\n",
        "\n",
        "log_reg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = log_reg_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# -----------------------------------\n",
        "# 4. Print results\n",
        "# -----------------------------------\n",
        "print(\"\\n--- Minimal Burnout Model ---\")\n",
        "print(\"Chosen Original Features:\", original_top3_features)\n",
        "print(\"Accuracy on Test Set: {:.3f}%\".format(accuracy * 100))\n",
        "\n",
        "#Cross-validation for robustness\n",
        "# Apply preprocessing before cross-validation\n",
        "X_top3_processed_cv = preprocessor_top3.fit_transform(X_top3_orig)\n",
        "cv_scores = cross_val_score(LogisticRegression(max_iter=1500, random_state=46), X_top3_processed_cv, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross-Validation Accuracy: {:.2f}% (+/- {:.2f}%)\".format(cv_scores.mean()*100, cv_scores.std()*100))\n",
        "\n",
        "# -----------------------------------\n",
        "# 5. Reasoning\n",
        "# -----------------------------------\n",
        "print(\"The selected top 3 features are likely  to be strong indicators of burnout risk based on Random Forest's conclusion of their predictive power.\")\n",
        "print(\"Training a minimal model on these features helps understand the core drivers of burnout in the dataset and potentially uilding a simpler,more  interpretabble model\")\n"
      ]
    }
  ]
}
